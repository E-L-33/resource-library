# 数据分析预计基本路线

## 任职要求
- SQL数据库的基本操作，会基本的数据管理
- 会用Excel/SQL做基本的数据分析和展示
- 会用脚本语言进行数据分析，Python or R
- 有获取外部数据的能力，如爬虫
- 会基本的数据可视化技能，能撰写数据报告
- 熟悉常用的数据挖掘算法：以回归分析为主

## 数据分析流程

* 数据获取
	* 了解公开数据集的渠道
	* 爬虫
* 数据存储、提取
	* SQL实现数据存储、查询、提取
	* 数据库的分组、聚合
	* SQL建立多表联系
* 数据预处理
	* Python进行数据预处理
* 数据建模与分析
	* 统计学基础知识
	* 统计量的描述与展示
	* 假设检验
	* 常用的回归分析
	* 基本的分类聚合算法
	* 提升分析精度：特征工程
* 数据可视化
	* 用Python进行可视化分析
	* 分析结果展示、数据报告撰写

## 流程具体学习路径
### 数据获取
外部数据的获取方式主要有以下两种。
**第一种是获取外部的公开数据集**，一些科研机构、企业、政府会开放一些数据，你需要到特定的网站去下载这些数据。这些数据集通常比较完善、质量相对较高。推荐的一些常用可以获取数据集的网站：
- [UCI](http://archive.ics.uci.edu/ml/datasets.html)：加州大学欧文分校开放的经典数据集，被很多数据挖掘实验室采用。
- [国家数据](http://data.stats.gov.cn/)：数据来源于中国国家统计局，包含了我国经济民生等多个方面的数据。
- [CEIC](http://www.ceicdata.com/zh-hans)：超过128个国家的经济数据，能精确查找GDP、进出口零售，销售等深度数据。
- [中国统计信息网](http://www.tjcn.org/)：国家统计局官方网站，汇集了国民经济和社会发展统计信息。
- [优易数据](http://www.youedata.com/)：由国家信息中心发起，国内领先的数据交易平台，很多免费数据。

**第二种就是爬虫了，**Python常用于爬虫的库有urllib、BeautifulSoup、requests、scrapy

### 数据存取
数据存取：**Excel、SQL语言**
在应对万以内的数据的时候，**Excel**对于一般的分析没有问题，一旦数据量大，就会力不从心，数据库就能够很好地解决这个问题。而且大多数的企业，都会以SQL的形式来存储数据。

**数据库的增、删、查、改**：这些是数据库最基本的操作，但只要用简单的命令就能够实现，所以你只需要记住命令就好。

**数据的分组聚合、如何建立多个表之间的联系**：这个部分是SQL的进阶操作，多个表之间的关联，在你处理多维度、多个数据集的时候非常有用，这也让你可以去处理更复杂的数据。
	
SQL这部分比较简单，主要是掌握一些基本的语句。当然，还是建议你找几个**数据集**来实际操作一下，哪怕是最基础的查询、提取等。

### 数据预处理：Python（pandas）
很多时候我们拿到的数据是不干净的，**数据的重复、缺失、异常值等等**，这时候就需要进行数据的清洗，把这些影响分析的数据处理好，才能获得更加精确地分析结果。

比如销售数据，有一些渠道的销售是没有及时录入的，有一些数据是记录重复的。比如用户行为数据，有很多无效的操作对分析没有意义，就需要进行删除。

那么我们需要用相应的方法去处理，比如残缺数据，我们是直接去掉这条数据，还是用临近的值去补全，这些都是需要考虑的问题。
对于数据预处理，学会pandas(Python包)的用法，应对一般的数据清洗就完全没问题了。需要掌握的知识点如下：

- 选择：数据访问（标签、特定值、布尔索引等）
- 缺失值处理：对缺失数据行进行删除或填充
- 重复值处理：重复值的判断与删除
- 异常值处理：清除不必要的空格和极端、异常数据
- 相关操作：描述性统计、Apply、直方图等
- 合并：符合各种逻辑关系的合并操作
- 分组：数据划分、分别执行函数、数据重组
- Reshaping：快速生成数据透视表

都非常简单，可查 pandas 官方文档。

### 概率论及统计学知识
数据整体分布是怎样的？什么是总体和样本？中位数、众数、均值、方差等基本的统计量如何应用？如何在不同的场景中做假设检验？数据分析方法大多源于统计学的概念，所以统计学的知识也是必不可少的。需要掌握的知识点如下：

- 基本统计量：均值、中位数、众数、百分位数、极值等
- 其他描述性统计量：偏度、方差、标准差、显著性等
- 其他统计知识：总体和样本、参数和统计量、ErrorBar
- 概率分布与假设检验：各种分布、假设检验流程
- 其他概率论知识：条件概率、贝叶斯等


有了统计学的基本知识，你就可以用这些统计量做基本的分析了。通过可视化的方式来描述数据的指标，其实可以得出很多结论了：比如排名前100的是哪些，平均水平是怎样的，近几年的变化趋势如何……

你可以使用**Seaborn、matplotlib**等（python包）做一些可视化的分析，通过各种可视化统计图，并得出具有指导意义的结果。

### Python 数据分析
如果你有一些了解的话，就知道目前市面上其实有很多 Python 数据分析的书籍，但每一本都很厚，学习阻力非常大。但其实真正最有用的那部分信息，只是这些书里很少的一部分。

比如掌握回归分析的方法，通过线性回归和逻辑回归，其实你就可以对大多数的数据进行回归分析，并得出相对精确地结论。这部分需要掌握的知识点如下：

- 回归分析：线性回归、逻辑回归
- 基本的分类算法：决策树、随机森林……
- 基本的聚类算法：k-means……
- 特征工程基础：如何用特征选择优化模型
- 调参方法：如何调节参数优化模型
- Python 数据分析包：scipy、numpy、scikit-learn等


在数据分析的这个阶段，重点了解回归分析的方法，大多数的问题可以得以解决，利用描述性的统计分析和回归分析，你完全可以得到一个不错的分析结论。

然后你会知道面对不同类型的问题的时候更适合用哪种算法模型，对于模型的优化，你需要去学习如何通过特征提取、参数调节来提升预测的精度。这就有点数据挖掘和机器学习的味道了，其实一个好的数据分析师，应该算是一个初级的数据挖掘工程师了。

你可以通过Python中的**scikit-learn**库来实现数据分析、数据挖掘建模和分析的全过程。

### 系统实战与数据思维
到这个时候，你就已经具备了数据分析的基本能力了。但是还要根据不同的案例、不同的业务场景进行实战，练习解决实际问题的能力。
上面提到的公开数据集，可以找一些自己感兴趣的方向的数据，尝试从不同的角度来分析，看看能够得到哪些有价值的结论。
你也可以从生活、工作中去发现一些可用于分析的问题，比如上面说到的电商、招聘、社交等平台等数据中都有着很多可以挖掘的问题。
开始的时候，你可能考虑的问题不是很周全，但随着你经验的积累，慢慢就会找到分析的方向，有哪些一般分析的维度，比如Top榜单、平均水平、区域分布、同比环比、相关性分析、未来趋势预测等等。随着经验的增加，你会有一些自己对于数据的感觉，这就是我们通常说的数据思维了。

